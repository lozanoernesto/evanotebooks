[
  {
    "id": "F9h3k0t9ST",
    "type": "toc",
    "data": {
      "items": [
        {
          "id": "scxkahft9s",
          "reference": "V790qmV3Ym",
          "text": "Track human from image",
          "level": 1
        },
        {
          "id": "2z2jmwx0mg",
          "reference": "wirInDdcHN",
          "text": "Track aliveness human",
          "level": 1
        },
        {
          "id": "3947yaqm5w",
          "reference": "XjqJQcINAA",
          "text": "Track aliveness human with MQTT and EVA",
          "level": 1
        },
        {
          "id": "ifwk5cwiut",
          "reference": "pDqGq08a4s",
          "text": "Replication",
          "level": 1
        }
      ]
    },
    "index": 0,
    "createdBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
    "topic": "24e59b27-632c-46f6-8b46-123d3e92815b",
    "crdts": {
      "operations": [
        [
          {
            "creator": "fvaguydpuy",
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "id": "F9h3k0t9ST",
                    "type": "toc",
                    "data": {
                      "items": [
                        {
                          "id": "scxkahft9s",
                          "reference": "V790qmV3Ym",
                          "text": "Track human from image",
                          "level": 1
                        },
                        {
                          "id": "2z2jmwx0mg",
                          "reference": "wirInDdcHN",
                          "text": "Track aliveness human",
                          "level": 1
                        },
                        {
                          "id": "3947yaqm5w",
                          "reference": "XjqJQcINAA",
                          "text": "Track aliveness human with MQTT and EVA",
                          "level": 1
                        },
                        {
                          "id": "ifwk5cwiut",
                          "reference": "pDqGq08a4s",
                          "text": "Replication",
                          "level": 1
                        }
                      ]
                    },
                    "index": 0,
                    "createdBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "topic": "24e59b27-632c-46f6-8b46-123d3e92815b"
                  }
                }
              }
            ],
            "time": 1684618359669.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "index": 0
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618537728.01
          }
        ]
      ],
      "hash": "e07cb87d1b0425f28cea9900c006b1fed995d1c051d6d6bcbbcec85ad952dd5f"
    },
    "_meta": {
      "lwt": 1684618537729.01
    },
    "_deleted": false,
    "_attachments": {},
    "_rev": "2-alwuqujhxp"
  },
  {
    "id": "sxLXPHuOHE",
    "type": "header",
    "data": {
      "text": "Track human from image",
      "level": 1
    },
    "index": 1,
    "createdBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
    "topic": "24e59b27-632c-46f6-8b46-123d3e92815b",
    "crdts": {
      "operations": [
        [
          {
            "creator": "fvaguydpuy",
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "id": "sxLXPHuOHE",
                    "type": "header",
                    "data": {
                      "text": "Track human from image",
                      "level": 1
                    },
                    "index": 1,
                    "createdBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "topic": "24e59b27-632c-46f6-8b46-123d3e92815b"
                  }
                }
              }
            ],
            "time": 1684618359669.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "index": 1
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618537822.02
          }
        ]
      ],
      "hash": "e07cb87d1b0425f28cea9900c006b1fed995d1c051d6d6bcbbcec85ad952dd5f"
    },
    "_meta": {
      "lwt": 1684618537824.03
    },
    "_deleted": false,
    "_attachments": {},
    "_rev": "2-alwuqujhxp"
  },
  {
    "id": "Lo2IdbG4oW",
    "type": "code",
    "data": {
      "code": "`<img id=\"webcam\" crossorigin src=\"https://www.gannett-cdn.com/presto/2021/01/27/PMCA/3b34404e-8401-4a6d-9d30-38dbe9a274d4-244ff25c-ef77-4d64-9bbc-d0e64ea6de3e_thumbnail.png?width=1280&height=720&fit=crop&format=pjpg&auto=webp\">`",
      "language": "javascript",
      "output": ""
    },
    "index": 2,
    "createdBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
    "topic": "24e59b27-632c-46f6-8b46-123d3e92815b",
    "crdts": {
      "operations": [
        [
          {
            "creator": "fvaguydpuy",
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "id": "Lo2IdbG4oW",
                    "type": "code",
                    "data": {
                      "code": "`<img id=\"webcam\" crossorigin src=\"https://www.gannett-cdn.com/presto/2021/01/27/PMCA/3b34404e-8401-4a6d-9d30-38dbe9a274d4-244ff25c-ef77-4d64-9bbc-d0e64ea6de3e_thumbnail.png?width=1280&height=720&fit=crop&format=pjpg&auto=webp\">`",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 2,
                    "createdBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "topic": "24e59b27-632c-46f6-8b46-123d3e92815b"
                  }
                }
              }
            ],
            "time": 1684618359669.03
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "index": 2
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618537823.01
          }
        ]
      ],
      "hash": "e07cb87d1b0425f28cea9900c006b1fed995d1c051d6d6bcbbcec85ad952dd5f"
    },
    "_meta": {
      "lwt": 1684618537824.04
    },
    "_deleted": false,
    "_attachments": {},
    "_rev": "2-alwuqujhxp"
  },
  {
    "id": "1zoO1JhKJt",
    "type": "code",
    "data": {
      "code": "`\n<section>\n<canvas id=\"canvas\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"left\" : \"right\";\n  alert(action);\n</script>\n</section>\n`",
      "language": "javascript",
      "output": ""
    },
    "index": 3,
    "createdBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
    "topic": "24e59b27-632c-46f6-8b46-123d3e92815b",
    "crdts": {
      "operations": [
        [
          {
            "creator": "fvaguydpuy",
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "id": "1zoO1JhKJt",
                    "type": "code",
                    "data": {
                      "code": "`\n<section>\n<canvas id=\"canvas\"></canvas>\n<script type=\"module\">\n  const canvas = document.getElementById(\"canvas\");\n  const img = document.getElementById('webcam');\n  const ctx = canvas.getContext('2d');\n  canvas.width = img.width;\n  canvas.height = img.height;\n  ctx.drawImage(img, 0, 0, img.width, img.height);\n  ctx.beginPath();\n  ctx.moveTo(img.width/2, 0);\n  ctx.lineTo(img.width/2, img.height);\n  ctx.stroke();\n  import vision from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n  const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;\n  let faceLandmarker;\n  let runningMode = \"IMAGE\";\n  const filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  function calculateCentroid(landmarks) {\n     const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x+acc[0];\n        acc[1] = landmark.y+acc[1];\n        acc[2] = landmark.z+acc[2];\n        return acc;\n     }, [0,0,0]);\n     return sum.map(coord => coord / landmarks.length);\n  }\n  faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n      modelAssetPath: \n      \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n      delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: true,\n    runningMode,\n    numFaces: 1\n  });\n  const centroid = calculateCentroid(faceLandmarker.detect(img).faceLandmarks[0]);\n  const vcentroid = [centroid[0]*img.width,centroid[1]*img.height];\n  ctx.beginPath();\n  ctx.arc(vcentroid[0], vcentroid[1], 10, 0, 2*Math.PI, true);\n  ctx.fill();\n  const visionLine = 0.5;\n  const distance = visionLine-centroid[0];\n  const relativeDistance = Math.abs(distance)/centroid[0];\n  const threshold = 0.7;\n  const action = relativeDistance >= threshold ? \"NONE\" : distance > 0 ? \"left\" : \"right\";\n  alert(action);\n</script>\n</section>\n`",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 3,
                    "createdBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "topic": "24e59b27-632c-46f6-8b46-123d3e92815b"
                  }
                }
              }
            ],
            "time": 1684618359669.04
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "index": 3
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618537823.02
          }
        ]
      ],
      "hash": "e07cb87d1b0425f28cea9900c006b1fed995d1c051d6d6bcbbcec85ad952dd5f"
    },
    "_meta": {
      "lwt": 1684618537824.05
    },
    "_deleted": false,
    "_attachments": {},
    "_rev": "2-alwuqujhxp"
  },
  {
    "id": "gAE_-j5CYK",
    "type": "header",
    "data": {
      "text": "Track aliveness human",
      "level": 1
    },
    "index": 4,
    "createdBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
    "topic": "24e59b27-632c-46f6-8b46-123d3e92815b",
    "crdts": {
      "operations": [
        [
          {
            "creator": "fvaguydpuy",
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "id": "gAE_-j5CYK",
                    "type": "header",
                    "data": {
                      "text": "Track aliveness human",
                      "level": 1
                    },
                    "index": 4,
                    "createdBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "topic": "24e59b27-632c-46f6-8b46-123d3e92815b"
                  }
                }
              }
            ],
            "time": 1684618359669.05
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "index": 4
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618537823.03
          }
        ]
      ],
      "hash": "e07cb87d1b0425f28cea9900c006b1fed995d1c051d6d6bcbbcec85ad952dd5f"
    },
    "_meta": {
      "lwt": 1684618537824.06
    },
    "_deleted": false,
    "_attachments": {},
    "_rev": "2-alwuqujhxp"
  },
  {
    "id": "DhwTf6jyc-",
    "type": "code",
    "data": {
      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: false,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
      "language": "javascript",
      "output": "NONE"
    },
    "index": 5,
    "createdBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
    "topic": "24e59b27-632c-46f6-8b46-123d3e92815b",
    "crdts": {
      "operations": [
        [
          {
            "creator": "fvaguydpuy",
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "id": "DhwTf6jyc-",
                    "type": "code",
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: false,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.2;\n\ncaptureStream().pipe(\n  throttleTime(1000),\n  map(({message: img}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0)\n        return \"c\";\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    return relativeDistance <= threshold ? \"NONE\" : distance > 0 ? \"l\" : \"r\";\n  }),\n  rewrite()\n)",
                      "language": "javascript",
                      "output": "NONE"
                    },
                    "index": 5,
                    "createdBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "topic": "24e59b27-632c-46f6-8b46-123d3e92815b"
                  }
                }
              }
            ],
            "time": 1684618359669.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "index": 5
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618537823.04
          }
        ]
      ],
      "hash": "e07cb87d1b0425f28cea9900c006b1fed995d1c051d6d6bcbbcec85ad952dd5f"
    },
    "_meta": {
      "lwt": 1684618537824.07
    },
    "_deleted": false,
    "_attachments": {},
    "_rev": "2-alwuqujhxp"
  },
  {
    "id": "o9i6KRRs2Z",
    "type": "header",
    "data": {
      "text": "Track aliveness human with MQTT and EVA",
      "level": 1
    },
    "index": 6,
    "createdBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
    "topic": "24e59b27-632c-46f6-8b46-123d3e92815b",
    "crdts": {
      "operations": [
        [
          {
            "creator": "fvaguydpuy",
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "id": "o9i6KRRs2Z",
                    "type": "header",
                    "data": {
                      "text": "Track aliveness human with MQTT and EVA",
                      "level": 1
                    },
                    "index": 6,
                    "createdBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "topic": "24e59b27-632c-46f6-8b46-123d3e92815b"
                  }
                }
              }
            ],
            "time": 1684618359669.07
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "index": 6
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618537823.05
          }
        ]
      ],
      "hash": "e07cb87d1b0425f28cea9900c006b1fed995d1c051d6d6bcbbcec85ad952dd5f"
    },
    "_meta": {
      "lwt": 1684618537824.08
    },
    "_deleted": false,
    "_attachments": {},
    "_rev": "2-alwuqujhxp"
  },
  {
    "id": "7SDx1hrO53",
    "type": "code",
    "data": {
      "code": "import {\n  PoseLandmarker,\n  FilesetResolver,\n  DrawingUtils\n} from \"https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n\nconst poseLandmarker = await PoseLandmarker.createFromOptions(vision, {\n    baseOptions: {\n      modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task`,\n      delegate: \"GPU\"\n    },\n    runningMode: \"IMAGE\",\n    numPoses: 2\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.3;\n\n\nconst greetings = [\n  \"Hola, que puedo hacer por ti hoy?\",\n  \"Buenas tardes\",\n  \"Estimado, como puedo ayudarte?\",\n  \"Hola, por que me miras? Se que soy hermosa, pero no me mires asi\",\n  \"Hola, no me mires asi porque me desgasto\"\n]\n\n\nconnect(\"MQTT\", {\n  ...environment.mqtt,\n  topic: \"eva/camera/image\"\n}).pipe(\n  filter(x => x.message),\n  throttleTime(200),\n  base64ToBlob(),\n  blobToImage,\n  map(({message: img, connection}) => {\n    const landmarks = poseLandmarker.detect(img).landmarks;\n    if (landmarks.length === 0) {\n      connection.send({topic: \"eva/neck/animation\", message:  \"c\"});\n      return {message: null, connection};\n    }\n    const [x,y,z] = calculateCentroid(landmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    if (relativeDistance <= threshold)\n      return {message: null, connection};\n    connection.send({topic: \"eva/neck/animation\", message:  distance > 0 ? \"r\" : \"l\"});\n    return {message: math.distance([x,y,z], [0,0,0]), connection};\n  }),\n  filter(x => x.message && x.message <= 1.2),\n  throttleTime(7000),\n  tap(({connection}) => {\n    connection.send({topic: \"hermes/tts/say\", message: serialize({text: greetings[randint(0,greetings.length)]})})\n  })\n)",
      "language": "javascript",
      "output": ""
    },
    "index": 7,
    "createdBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
    "topic": "24e59b27-632c-46f6-8b46-123d3e92815b",
    "crdts": {
      "operations": [
        [
          {
            "creator": "fvaguydpuy",
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "id": "7SDx1hrO53",
                    "type": "code",
                    "data": {
                      "code": "import {\n    FaceLandmarker,\n    FilesetResolver,\n    DrawingUtils\n} from \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: false,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.3;\n\n\nconst greetings = [\n  \"Hola, que puedo hacer por ti hoy?\",\n  \"Buenas tardes\",\n  \"Estimado, como puedo ayudarte?\",\n  \"Hola, por que me miras? Se que soy hermosa, pero no me mires asi\",\n  \"Hola, no me mires asi porque me desgasto\"\n]\n\n\nconnect(\"MQTT\", {\n  ...environment.mqtt,\n  topic: \"eva/camera/image\"\n}).pipe(\n  filter(x => x.message),\n  throttleTime(200),\n  base64ToBlob(),\n  blobToImage,\n  map(({message: img, connection}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0) {\n      connection.send({topic: \"eva/neck/animation\", message:  \"c\"});\n      return {message: null, connection};\n    }\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    if (relativeDistance <= threshold)\n      return {message: null, connection};\n    connection.send({topic: \"eva/neck/animation\", message:  distance > 0 ? \"r\" : \"l\"});\n    return {message: math.distance([x,y,z], [0,0,0]), connection};\n  }),\n  filter(x => x.message && x.message <= 1.2),\n  throttleTime(7000),\n  tap(({connection}) => {\n    connection.send({topic: \"hermes/tts/say\", message: serialize({text: greetings[randint(0,greetings.length)]})})\n  })\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 7,
                    "createdBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "topic": "24e59b27-632c-46f6-8b46-123d3e92815b"
                  }
                }
              }
            ],
            "time": 1684618359669.08
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "\nimport {\n  PoseLandmarker,\n  FilesetResolver,\n  DrawingUtils\n} from \"https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: false,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.3;\n\n\nconst greetings = [\n  \"Hola, que puedo hacer por ti hoy?\",\n  \"Buenas tardes\",\n  \"Estimado, como puedo ayudarte?\",\n  \"Hola, por que me miras? Se que soy hermosa, pero no me mires asi\",\n  \"Hola, no me mires asi porque me desgasto\"\n]\n\n\nconnect(\"MQTT\", {\n  ...environment.mqtt,\n  topic: \"eva/camera/image\"\n}).pipe(\n  filter(x => x.message),\n  throttleTime(200),\n  base64ToBlob(),\n  blobToImage,\n  map(({message: img, connection}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0) {\n      connection.send({topic: \"eva/neck/animation\", message:  \"c\"});\n      return {message: null, connection};\n    }\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    if (relativeDistance <= threshold)\n      return {message: null, connection};\n    connection.send({topic: \"eva/neck/animation\", message:  distance > 0 ? \"r\" : \"l\"});\n    return {message: math.distance([x,y,z], [0,0,0]), connection};\n  }),\n  filter(x => x.message && x.message <= 1.2),\n  throttleTime(7000),\n  tap(({connection}) => {\n    connection.send({topic: \"hermes/tts/say\", message: serialize({text: greetings[randint(0,greetings.length)]})})\n  })\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 7,
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618382428.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n  PoseLandmarker,\n  FilesetResolver,\n  DrawingUtils\n} from \"https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {\n    baseOptions: {\n        modelAssetPath: \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\",\n        delegate: \"GPU\"\n    },\n    outputFaceBlendshapes: false,\n    runningMode: \"IMAGE\",\n    numFaces: 1\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.3;\n\n\nconst greetings = [\n  \"Hola, que puedo hacer por ti hoy?\",\n  \"Buenas tardes\",\n  \"Estimado, como puedo ayudarte?\",\n  \"Hola, por que me miras? Se que soy hermosa, pero no me mires asi\",\n  \"Hola, no me mires asi porque me desgasto\"\n]\n\n\nconnect(\"MQTT\", {\n  ...environment.mqtt,\n  topic: \"eva/camera/image\"\n}).pipe(\n  filter(x => x.message),\n  throttleTime(200),\n  base64ToBlob(),\n  blobToImage,\n  map(({message: img, connection}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0) {\n      connection.send({topic: \"eva/neck/animation\", message:  \"c\"});\n      return {message: null, connection};\n    }\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    if (relativeDistance <= threshold)\n      return {message: null, connection};\n    connection.send({topic: \"eva/neck/animation\", message:  distance > 0 ? \"r\" : \"l\"});\n    return {message: math.distance([x,y,z], [0,0,0]), connection};\n  }),\n  filter(x => x.message && x.message <= 1.2),\n  throttleTime(7000),\n  tap(({connection}) => {\n    connection.send({topic: \"hermes/tts/say\", message: serialize({text: greetings[randint(0,greetings.length)]})})\n  })\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 7,
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618384282.05
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n  PoseLandmarker,\n  FilesetResolver,\n  DrawingUtils\n} from \"https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\n  const vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  poseLandmarker = await PoseLandmarker.createFromOptions(vision, {\n    baseOptions: {\n      modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task`,\n      delegate: \"GPU\"\n    },\n    runningMode: runningMode,\n    numPoses: 2\n  });\n\n\nconst visionLine = 0.5;\nconst threshold = 0.3;\n\n\nconst greetings = [\n  \"Hola, que puedo hacer por ti hoy?\",\n  \"Buenas tardes\",\n  \"Estimado, como puedo ayudarte?\",\n  \"Hola, por que me miras? Se que soy hermosa, pero no me mires asi\",\n  \"Hola, no me mires asi porque me desgasto\"\n]\n\n\nconnect(\"MQTT\", {\n  ...environment.mqtt,\n  topic: \"eva/camera/image\"\n}).pipe(\n  filter(x => x.message),\n  throttleTime(200),\n  base64ToBlob(),\n  blobToImage,\n  map(({message: img, connection}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0) {\n      connection.send({topic: \"eva/neck/animation\", message:  \"c\"});\n      return {message: null, connection};\n    }\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    if (relativeDistance <= threshold)\n      return {message: null, connection};\n    connection.send({topic: \"eva/neck/animation\", message:  distance > 0 ? \"r\" : \"l\"});\n    return {message: math.distance([x,y,z], [0,0,0]), connection};\n  }),\n  filter(x => x.message && x.message <= 1.2),\n  throttleTime(7000),\n  tap(({connection}) => {\n    connection.send({topic: \"hermes/tts/say\", message: serialize({text: greetings[randint(0,greetings.length)]})})\n  })\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 7,
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618391099.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n  PoseLandmarker,\n  FilesetResolver,\n  DrawingUtils\n} from \"https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n  poseLandmarker = await PoseLandmarker.createFromOptions(vision, {\n    baseOptions: {\n      modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task`,\n      delegate: \"GPU\"\n    },\n    runningMode: runningMode,\n    numPoses: 2\n  });\n\n\nconst visionLine = 0.5;\nconst threshold = 0.3;\n\n\nconst greetings = [\n  \"Hola, que puedo hacer por ti hoy?\",\n  \"Buenas tardes\",\n  \"Estimado, como puedo ayudarte?\",\n  \"Hola, por que me miras? Se que soy hermosa, pero no me mires asi\",\n  \"Hola, no me mires asi porque me desgasto\"\n]\n\n\nconnect(\"MQTT\", {\n  ...environment.mqtt,\n  topic: \"eva/camera/image\"\n}).pipe(\n  filter(x => x.message),\n  throttleTime(200),\n  base64ToBlob(),\n  blobToImage,\n  map(({message: img, connection}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0) {\n      connection.send({topic: \"eva/neck/animation\", message:  \"c\"});\n      return {message: null, connection};\n    }\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    if (relativeDistance <= threshold)\n      return {message: null, connection};\n    connection.send({topic: \"eva/neck/animation\", message:  distance > 0 ? \"r\" : \"l\"});\n    return {message: math.distance([x,y,z], [0,0,0]), connection};\n  }),\n  filter(x => x.message && x.message <= 1.2),\n  throttleTime(7000),\n  tap(({connection}) => {\n    connection.send({topic: \"hermes/tts/say\", message: serialize({text: greetings[randint(0,greetings.length)]})})\n  })\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 7,
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618392459.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n  PoseLandmarker,\n  FilesetResolver,\n  DrawingUtils\n} from \"https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\nposeLandmarker = await PoseLandmarker.createFromOptions(vision, {\n    baseOptions: {\n      modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task`,\n      delegate: \"GPU\"\n    },\n    runningMode: runningMode,\n    numPoses: 2\n  });\n\n\nconst visionLine = 0.5;\nconst threshold = 0.3;\n\n\nconst greetings = [\n  \"Hola, que puedo hacer por ti hoy?\",\n  \"Buenas tardes\",\n  \"Estimado, como puedo ayudarte?\",\n  \"Hola, por que me miras? Se que soy hermosa, pero no me mires asi\",\n  \"Hola, no me mires asi porque me desgasto\"\n]\n\n\nconnect(\"MQTT\", {\n  ...environment.mqtt,\n  topic: \"eva/camera/image\"\n}).pipe(\n  filter(x => x.message),\n  throttleTime(200),\n  base64ToBlob(),\n  blobToImage,\n  map(({message: img, connection}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0) {\n      connection.send({topic: \"eva/neck/animation\", message:  \"c\"});\n      return {message: null, connection};\n    }\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    if (relativeDistance <= threshold)\n      return {message: null, connection};\n    connection.send({topic: \"eva/neck/animation\", message:  distance > 0 ? \"r\" : \"l\"});\n    return {message: math.distance([x,y,z], [0,0,0]), connection};\n  }),\n  filter(x => x.message && x.message <= 1.2),\n  throttleTime(7000),\n  tap(({connection}) => {\n    connection.send({topic: \"hermes/tts/say\", message: serialize({text: greetings[randint(0,greetings.length)]})})\n  })\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 7,
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618399332.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n  PoseLandmarker,\n  FilesetResolver,\n  DrawingUtils\n} from \"https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n\nposeLandmarker = await PoseLandmarker.createFromOptions(vision, {\n    baseOptions: {\n      modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task`,\n      delegate: \"GPU\"\n    },\n    runningMode: runningMode,\n    numPoses: 2\n  });\n\n\nconst visionLine = 0.5;\nconst threshold = 0.3;\n\n\nconst greetings = [\n  \"Hola, que puedo hacer por ti hoy?\",\n  \"Buenas tardes\",\n  \"Estimado, como puedo ayudarte?\",\n  \"Hola, por que me miras? Se que soy hermosa, pero no me mires asi\",\n  \"Hola, no me mires asi porque me desgasto\"\n]\n\n\nconnect(\"MQTT\", {\n  ...environment.mqtt,\n  topic: \"eva/camera/image\"\n}).pipe(\n  filter(x => x.message),\n  throttleTime(200),\n  base64ToBlob(),\n  blobToImage,\n  map(({message: img, connection}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0) {\n      connection.send({topic: \"eva/neck/animation\", message:  \"c\"});\n      return {message: null, connection};\n    }\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    if (relativeDistance <= threshold)\n      return {message: null, connection};\n    connection.send({topic: \"eva/neck/animation\", message:  distance > 0 ? \"r\" : \"l\"});\n    return {message: math.distance([x,y,z], [0,0,0]), connection};\n  }),\n  filter(x => x.message && x.message <= 1.2),\n  throttleTime(7000),\n  tap(({connection}) => {\n    connection.send({topic: \"hermes/tts/say\", message: serialize({text: greetings[randint(0,greetings.length)]})})\n  })\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 7,
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618399962.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n  PoseLandmarker,\n  FilesetResolver,\n  DrawingUtils\n} from \"https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n\nconst poseLandmarker = await PoseLandmarker.createFromOptions(vision, {\n    baseOptions: {\n      modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task`,\n      delegate: \"GPU\"\n    },\n    runningMode: runningMode,\n    numPoses: 2\n  });\n\n\nconst visionLine = 0.5;\nconst threshold = 0.3;\n\n\nconst greetings = [\n  \"Hola, que puedo hacer por ti hoy?\",\n  \"Buenas tardes\",\n  \"Estimado, como puedo ayudarte?\",\n  \"Hola, por que me miras? Se que soy hermosa, pero no me mires asi\",\n  \"Hola, no me mires asi porque me desgasto\"\n]\n\n\nconnect(\"MQTT\", {\n  ...environment.mqtt,\n  topic: \"eva/camera/image\"\n}).pipe(\n  filter(x => x.message),\n  throttleTime(200),\n  base64ToBlob(),\n  blobToImage,\n  map(({message: img, connection}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0) {\n      connection.send({topic: \"eva/neck/animation\", message:  \"c\"});\n      return {message: null, connection};\n    }\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    if (relativeDistance <= threshold)\n      return {message: null, connection};\n    connection.send({topic: \"eva/neck/animation\", message:  distance > 0 ? \"r\" : \"l\"});\n    return {message: math.distance([x,y,z], [0,0,0]), connection};\n  }),\n  filter(x => x.message && x.message <= 1.2),\n  throttleTime(7000),\n  tap(({connection}) => {\n    connection.send({topic: \"hermes/tts/say\", message: serialize({text: greetings[randint(0,greetings.length)]})})\n  })\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 7,
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618401243.03
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n  PoseLandmarker,\n  FilesetResolver,\n  DrawingUtils\n} from \"https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n\nconst poseLandmarker = await PoseLandmarker.createFromOptions(vision, {\n    baseOptions: {\n      modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task`,\n      delegate: \"GPU\"\n    },\n    runningMode: runningMode,\n    numPoses: 2\n0  });\n\n\nconst visionLine = 0.5;\nconst threshold = 0.3;\n\n\nconst greetings = [\n  \"Hola, que puedo hacer por ti hoy?\",\n  \"Buenas tardes\",\n  \"Estimado, como puedo ayudarte?\",\n  \"Hola, por que me miras? Se que soy hermosa, pero no me mires asi\",\n  \"Hola, no me mires asi porque me desgasto\"\n]\n\n\nconnect(\"MQTT\", {\n  ...environment.mqtt,\n  topic: \"eva/camera/image\"\n}).pipe(\n  filter(x => x.message),\n  throttleTime(200),\n  base64ToBlob(),\n  blobToImage,\n  map(({message: img, connection}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0) {\n      connection.send({topic: \"eva/neck/animation\", message:  \"c\"});\n      return {message: null, connection};\n    }\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    if (relativeDistance <= threshold)\n      return {message: null, connection};\n    connection.send({topic: \"eva/neck/animation\", message:  distance > 0 ? \"r\" : \"l\"});\n    return {message: math.distance([x,y,z], [0,0,0]), connection};\n  }),\n  filter(x => x.message && x.message <= 1.2),\n  throttleTime(7000),\n  tap(({connection}) => {\n    connection.send({topic: \"hermes/tts/say\", message: serialize({text: greetings[randint(0,greetings.length)]})})\n  })\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 7,
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618407681.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n  PoseLandmarker,\n  FilesetResolver,\n  DrawingUtils\n} from \"https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n\nconst poseLandmarker = await PoseLandmarker.createFromOptions(vision, {\n    baseOptions: {\n      modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task`,\n      delegate: \"GPU\"\n    },\n    runningMode: runningMode,\n    numPoses: 2\n  });\n\n\nconst visionLine = 0.5;\nconst threshold = 0.3;\n\n\nconst greetings = [\n  \"Hola, que puedo hacer por ti hoy?\",\n  \"Buenas tardes\",\n  \"Estimado, como puedo ayudarte?\",\n  \"Hola, por que me miras? Se que soy hermosa, pero no me mires asi\",\n  \"Hola, no me mires asi porque me desgasto\"\n]\n\n\nconnect(\"MQTT\", {\n  ...environment.mqtt,\n  topic: \"eva/camera/image\"\n}).pipe(\n  filter(x => x.message),\n  throttleTime(200),\n  base64ToBlob(),\n  blobToImage,\n  map(({message: img, connection}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0) {\n      connection.send({topic: \"eva/neck/animation\", message:  \"c\"});\n      return {message: null, connection};\n    }\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    if (relativeDistance <= threshold)\n      return {message: null, connection};\n    connection.send({topic: \"eva/neck/animation\", message:  distance > 0 ? \"r\" : \"l\"});\n    return {message: math.distance([x,y,z], [0,0,0]), connection};\n  }),\n  filter(x => x.message && x.message <= 1.2),\n  throttleTime(7000),\n  tap(({connection}) => {\n    connection.send({topic: \"hermes/tts/say\", message: serialize({text: greetings[randint(0,greetings.length)]})})\n  })\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 7,
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618408290.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n  PoseLandmarker,\n  FilesetResolver,\n  DrawingUtils\n} from \"https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n\nconst poseLandmarker = await PoseLandmarker.createFromOptions(vision, {\n    baseOptions: {\n      modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task`,\n      delegate: \"GPU\"\n    },\n    runningMode: runningMode,\n    numPoses: 2\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.3;\n\n\nconst greetings = [\n  \"Hola, que puedo hacer por ti hoy?\",\n  \"Buenas tardes\",\n  \"Estimado, como puedo ayudarte?\",\n  \"Hola, por que me miras? Se que soy hermosa, pero no me mires asi\",\n  \"Hola, no me mires asi porque me desgasto\"\n]\n\n\nconnect(\"MQTT\", {\n  ...environment.mqtt,\n  topic: \"eva/camera/image\"\n}).pipe(\n  filter(x => x.message),\n  throttleTime(200),\n  base64ToBlob(),\n  blobToImage,\n  map(({message: img, connection}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0) {\n      connection.send({topic: \"eva/neck/animation\", message:  \"c\"});\n      return {message: null, connection};\n    }\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    if (relativeDistance <= threshold)\n      return {message: null, connection};\n    connection.send({topic: \"eva/neck/animation\", message:  distance > 0 ? \"r\" : \"l\"});\n    return {message: math.distance([x,y,z], [0,0,0]), connection};\n  }),\n  filter(x => x.message && x.message <= 1.2),\n  throttleTime(7000),\n  tap(({connection}) => {\n    connection.send({topic: \"hermes/tts/say\", message: serialize({text: greetings[randint(0,greetings.length)]})})\n  })\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 7,
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618409394.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n  PoseLandmarker,\n  FilesetResolver,\n  DrawingUtils\n} from \"https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n\nconst poseLandmarker = await PoseLandmarker.createFromOptions(vision, {\n    baseOptions: {\n      modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task`,\n      delegate: \"GPU\"\n    },\n    runningMode: \"IMAGE\",\n    numPoses: 2\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.3;\n\n\nconst greetings = [\n  \"Hola, que puedo hacer por ti hoy?\",\n  \"Buenas tardes\",\n  \"Estimado, como puedo ayudarte?\",\n  \"Hola, por que me miras? Se que soy hermosa, pero no me mires asi\",\n  \"Hola, no me mires asi porque me desgasto\"\n]\n\n\nconnect(\"MQTT\", {\n  ...environment.mqtt,\n  topic: \"eva/camera/image\"\n}).pipe(\n  filter(x => x.message),\n  throttleTime(200),\n  base64ToBlob(),\n  blobToImage,\n  map(({message: img, connection}) => {\n    const faceLandmarks = faceLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0) {\n      connection.send({topic: \"eva/neck/animation\", message:  \"c\"});\n      return {message: null, connection};\n    }\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    if (relativeDistance <= threshold)\n      return {message: null, connection};\n    connection.send({topic: \"eva/neck/animation\", message:  distance > 0 ? \"r\" : \"l\"});\n    return {message: math.distance([x,y,z], [0,0,0]), connection};\n  }),\n  filter(x => x.message && x.message <= 1.2),\n  throttleTime(7000),\n  tap(({connection}) => {\n    connection.send({topic: \"hermes/tts/say\", message: serialize({text: greetings[randint(0,greetings.length)]})})\n  })\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 7,
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618415858.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n  PoseLandmarker,\n  FilesetResolver,\n  DrawingUtils\n} from \"https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n\nconst poseLandmarker = await PoseLandmarker.createFromOptions(vision, {\n    baseOptions: {\n      modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task`,\n      delegate: \"GPU\"\n    },\n    runningMode: \"IMAGE\",\n    numPoses: 2\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.3;\n\n\nconst greetings = [\n  \"Hola, que puedo hacer por ti hoy?\",\n  \"Buenas tardes\",\n  \"Estimado, como puedo ayudarte?\",\n  \"Hola, por que me miras? Se que soy hermosa, pero no me mires asi\",\n  \"Hola, no me mires asi porque me desgasto\"\n]\n\n\nconnect(\"MQTT\", {\n  ...environment.mqtt,\n  topic: \"eva/camera/image\"\n}).pipe(\n  filter(x => x.message),\n  throttleTime(200),\n  base64ToBlob(),\n  blobToImage,\n  map(({message: img, connection}) => {\n    const faceLandmarks = poseLandmarker.detect(img).faceLandmarks;\n    if (faceLandmarks.length === 0) {\n      connection.send({topic: \"eva/neck/animation\", message:  \"c\"});\n      return {message: null, connection};\n    }\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    if (relativeDistance <= threshold)\n      return {message: null, connection};\n    connection.send({topic: \"eva/neck/animation\", message:  distance > 0 ? \"r\" : \"l\"});\n    return {message: math.distance([x,y,z], [0,0,0]), connection};\n  }),\n  filter(x => x.message && x.message <= 1.2),\n  throttleTime(7000),\n  tap(({connection}) => {\n    connection.send({topic: \"hermes/tts/say\", message: serialize({text: greetings[randint(0,greetings.length)]})})\n  })\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 7,
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618447482.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "index": 7
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618537823.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n  PoseLandmarker,\n  FilesetResolver,\n  DrawingUtils\n} from \"https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n\nconst poseLandmarker = await PoseLandmarker.createFromOptions(vision, {\n    baseOptions: {\n      modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task`,\n      delegate: \"GPU\"\n    },\n    runningMode: \"IMAGE\",\n    numPoses: 2\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.3;\n\n\nconst greetings = [\n  \"Hola, que puedo hacer por ti hoy?\",\n  \"Buenas tardes\",\n  \"Estimado, como puedo ayudarte?\",\n  \"Hola, por que me miras? Se que soy hermosa, pero no me mires asi\",\n  \"Hola, no me mires asi porque me desgasto\"\n]\n\n\nconnect(\"MQTT\", {\n  ...environment.mqtt,\n  topic: \"eva/camera/image\"\n}).pipe(\n  filter(x => x.message),\n  throttleTime(200),\n  base64ToBlob(),\n  blobToImage,\n  map(({message: img, connection}) => {\n    const faceLandmarks = poseLandmarker.detect(img);\n    if (faceLandmarks.length === 0) {\n      connection.send({topic: \"eva/neck/animation\", message:  \"c\"});\n      return {message: null, connection};\n    }\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    if (relativeDistance <= threshold)\n      return {message: null, connection};\n    connection.send({topic: \"eva/neck/animation\", message:  distance > 0 ? \"r\" : \"l\"});\n    return {message: math.distance([x,y,z], [0,0,0]), connection};\n  }),\n  filter(x => x.message && x.message <= 1.2),\n  throttleTime(7000),\n  tap(({connection}) => {\n    connection.send({topic: \"hermes/tts/say\", message: serialize({text: greetings[randint(0,greetings.length)]})})\n  })\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 7,
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618645371.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n  PoseLandmarker,\n  FilesetResolver,\n  DrawingUtils\n} from \"https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n\nconst poseLandmarker = await PoseLandmarker.createFromOptions(vision, {\n    baseOptions: {\n      modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task`,\n      delegate: \"GPU\"\n    },\n    runningMode: \"IMAGE\",\n    numPoses: 2\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.3;\n\n\nconst greetings = [\n  \"Hola, que puedo hacer por ti hoy?\",\n  \"Buenas tardes\",\n  \"Estimado, como puedo ayudarte?\",\n  \"Hola, por que me miras? Se que soy hermosa, pero no me mires asi\",\n  \"Hola, no me mires asi porque me desgasto\"\n]\n\n\nconnect(\"MQTT\", {\n  ...environment.mqtt,\n  topic: \"eva/camera/image\"\n}).pipe(\n  filter(x => x.message),\n  throttleTime(200),\n  base64ToBlob(),\n  blobToImage,\n  map(({message: img, connection}) => {\n    const faceLandmarks = poseLandmarker.detect(img);\n    console.log\n    if (faceLandmarks.length === 0) {\n      connection.send({topic: \"eva/neck/animation\", message:  \"c\"});\n      return {message: null, connection};\n    }\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    if (relativeDistance <= threshold)\n      return {message: null, connection};\n    connection.send({topic: \"eva/neck/animation\", message:  distance > 0 ? \"r\" : \"l\"});\n    return {message: math.distance([x,y,z], [0,0,0]), connection};\n  }),\n  filter(x => x.message && x.message <= 1.2),\n  throttleTime(7000),\n  tap(({connection}) => {\n    connection.send({topic: \"hermes/tts/say\", message: serialize({text: greetings[randint(0,greetings.length)]})})\n  })\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 7,
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618648298.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n  PoseLandmarker,\n  FilesetResolver,\n  DrawingUtils\n} from \"https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n\nconst poseLandmarker = await PoseLandmarker.createFromOptions(vision, {\n    baseOptions: {\n      modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task`,\n      delegate: \"GPU\"\n    },\n    runningMode: \"IMAGE\",\n    numPoses: 2\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.3;\n\n\nconst greetings = [\n  \"Hola, que puedo hacer por ti hoy?\",\n  \"Buenas tardes\",\n  \"Estimado, como puedo ayudarte?\",\n  \"Hola, por que me miras? Se que soy hermosa, pero no me mires asi\",\n  \"Hola, no me mires asi porque me desgasto\"\n]\n\n\nconnect(\"MQTT\", {\n  ...environment.mqtt,\n  topic: \"eva/camera/image\"\n}).pipe(\n  filter(x => x.message),\n  throttleTime(200),\n  base64ToBlob(),\n  blobToImage,\n  map(({message: img, connection}) => {\n    const lan = poseLandmarker.detect(img);\n    console.log\n    if (faceLandmarks.length === 0) {\n      connection.send({topic: \"eva/neck/animation\", message:  \"c\"});\n      return {message: null, connection};\n    }\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    if (relativeDistance <= threshold)\n      return {message: null, connection};\n    connection.send({topic: \"eva/neck/animation\", message:  distance > 0 ? \"r\" : \"l\"});\n    return {message: math.distance([x,y,z], [0,0,0]), connection};\n  }),\n  filter(x => x.message && x.message <= 1.2),\n  throttleTime(7000),\n  tap(({connection}) => {\n    connection.send({topic: \"hermes/tts/say\", message: serialize({text: greetings[randint(0,greetings.length)]})})\n  })\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 7,
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618655515.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n  PoseLandmarker,\n  FilesetResolver,\n  DrawingUtils\n} from \"https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n\nconst poseLandmarker = await PoseLandmarker.createFromOptions(vision, {\n    baseOptions: {\n      modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task`,\n      delegate: \"GPU\"\n    },\n    runningMode: \"IMAGE\",\n    numPoses: 2\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.3;\n\n\nconst greetings = [\n  \"Hola, que puedo hacer por ti hoy?\",\n  \"Buenas tardes\",\n  \"Estimado, como puedo ayudarte?\",\n  \"Hola, por que me miras? Se que soy hermosa, pero no me mires asi\",\n  \"Hola, no me mires asi porque me desgasto\"\n]\n\n\nconnect(\"MQTT\", {\n  ...environment.mqtt,\n  topic: \"eva/camera/image\"\n}).pipe(\n  filter(x => x.message),\n  throttleTime(200),\n  base64ToBlob(),\n  blobToImage,\n  map(({message: img, connection}) => {\n    const landmarks = poseLandmarker.detect(img);\n    console.log\n    if (faceLandmarks.length === 0) {\n      connection.send({topic: \"eva/neck/animation\", message:  \"c\"});\n      return {message: null, connection};\n    }\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    if (relativeDistance <= threshold)\n      return {message: null, connection};\n    connection.send({topic: \"eva/neck/animation\", message:  distance > 0 ? \"r\" : \"l\"});\n    return {message: math.distance([x,y,z], [0,0,0]), connection};\n  }),\n  filter(x => x.message && x.message <= 1.2),\n  throttleTime(7000),\n  tap(({connection}) => {\n    connection.send({topic: \"hermes/tts/say\", message: serialize({text: greetings[randint(0,greetings.length)]})})\n  })\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 7,
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618656738.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n  PoseLandmarker,\n  FilesetResolver,\n  DrawingUtils\n} from \"https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n\nconst poseLandmarker = await PoseLandmarker.createFromOptions(vision, {\n    baseOptions: {\n      modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task`,\n      delegate: \"GPU\"\n    },\n    runningMode: \"IMAGE\",\n    numPoses: 2\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.3;\n\n\nconst greetings = [\n  \"Hola, que puedo hacer por ti hoy?\",\n  \"Buenas tardes\",\n  \"Estimado, como puedo ayudarte?\",\n  \"Hola, por que me miras? Se que soy hermosa, pero no me mires asi\",\n  \"Hola, no me mires asi porque me desgasto\"\n]\n\n\nconnect(\"MQTT\", {\n  ...environment.mqtt,\n  topic: \"eva/camera/image\"\n}).pipe(\n  filter(x => x.message),\n  throttleTime(200),\n  base64ToBlob(),\n  blobToImage,\n  map(({message: img, connection}) => {\n    const landmarks = poseLandmarker.detect(img);\n    console.log(landmarks)\n    if (faceLandmarks.length === 0) {\n      connection.send({topic: \"eva/neck/animation\", message:  \"c\"});\n      return {message: null, connection};\n    }\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    if (relativeDistance <= threshold)\n      return {message: null, connection};\n    connection.send({topic: \"eva/neck/animation\", message:  distance > 0 ? \"r\" : \"l\"});\n    return {message: math.distance([x,y,z], [0,0,0]), connection};\n  }),\n  filter(x => x.message && x.message <= 1.2),\n  throttleTime(7000),\n  tap(({connection}) => {\n    connection.send({topic: \"hermes/tts/say\", message: serialize({text: greetings[randint(0,greetings.length)]})})\n  })\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 7,
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618659409.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n  PoseLandmarker,\n  FilesetResolver,\n  DrawingUtils\n} from \"https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n\nconst poseLandmarker = await PoseLandmarker.createFromOptions(vision, {\n    baseOptions: {\n      modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task`,\n      delegate: \"GPU\"\n    },\n    runningMode: \"IMAGE\",\n    numPoses: 2\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.3;\n\n\nconst greetings = [\n  \"Hola, que puedo hacer por ti hoy?\",\n  \"Buenas tardes\",\n  \"Estimado, como puedo ayudarte?\",\n  \"Hola, por que me miras? Se que soy hermosa, pero no me mires asi\",\n  \"Hola, no me mires asi porque me desgasto\"\n]\n\n\nconnect(\"MQTT\", {\n  ...environment.mqtt,\n  topic: \"eva/camera/image\"\n}).pipe(\n  filter(x => x.message),\n  throttleTime(200),\n  base64ToBlob(),\n  blobToImage,\n  map(({message: img, connection}) => {\n    const landmarks = poseLandmarker.detect(img);\n    console.log(landmarks);\n    if (faceLandmarks.length === 0) {\n      connection.send({topic: \"eva/neck/animation\", message:  \"c\"});\n      return {message: null, connection};\n    }\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    if (relativeDistance <= threshold)\n      return {message: null, connection};\n    connection.send({topic: \"eva/neck/animation\", message:  distance > 0 ? \"r\" : \"l\"});\n    return {message: math.distance([x,y,z], [0,0,0]), connection};\n  }),\n  filter(x => x.message && x.message <= 1.2),\n  throttleTime(7000),\n  tap(({connection}) => {\n    connection.send({topic: \"hermes/tts/say\", message: serialize({text: greetings[randint(0,greetings.length)]})})\n  })\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 7,
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618660851.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n  PoseLandmarker,\n  FilesetResolver,\n  DrawingUtils\n} from \"https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n\nconst poseLandmarker = await PoseLandmarker.createFromOptions(vision, {\n    baseOptions: {\n      modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task`,\n      delegate: \"GPU\"\n    },\n    runningMode: \"IMAGE\",\n    numPoses: 2\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.3;\n\n\nconst greetings = [\n  \"Hola, que puedo hacer por ti hoy?\",\n  \"Buenas tardes\",\n  \"Estimado, como puedo ayudarte?\",\n  \"Hola, por que me miras? Se que soy hermosa, pero no me mires asi\",\n  \"Hola, no me mires asi porque me desgasto\"\n]\n\n\nconnect(\"MQTT\", {\n  ...environment.mqtt,\n  topic: \"eva/camera/image\"\n}).pipe(\n  filter(x => x.message),\n  throttleTime(200),\n  base64ToBlob(),\n  blobToImage,\n  map(({message: img, connection}) => {\n    const landmarks = poseLandmarker.detect(img);\n    console.log(landmarks);\n    if (faceLandmarks.length === 0) {\n      connection.send({topic: \"eva/neck/animation\", message:  \"c\"});\n      return {message: null, connection};\n    }\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    if (relativeDistance <= threshold)\n      return {message: null, connection};\n    connection.send({topic: \"eva/neck/animation\", message:  distance > 0 ? \"r\" : \"l\"});\n    return {message: math.distance([x,y,z], [0,0,0]), connection};\n  }),\n  filter(x => x.message && x.message <= 1.2),\n  throttleTime(7000),\n  tap(({connection}) => {\n    connection.send({topic: \"hermes/tts/say\", message: serialize({text: greetings[randint(0,greetings.length)]})})\n  })\n)",
                      "language": "javascript",
                      "output": "Uncaught ReferenceError: faceLandmarks is not defined\n"
                    },
                    "index": 7,
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618762546.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n  PoseLandmarker,\n  FilesetResolver,\n  DrawingUtils\n} from \"https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n\nconst poseLandmarker = await PoseLandmarker.createFromOptions(vision, {\n    baseOptions: {\n      modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task`,\n      delegate: \"GPU\"\n    },\n    runningMode: \"IMAGE\",\n    numPoses: 2\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.3;\n\n\nconst greetings = [\n  \"Hola, que puedo hacer por ti hoy?\",\n  \"Buenas tardes\",\n  \"Estimado, como puedo ayudarte?\",\n  \"Hola, por que me miras? Se que soy hermosa, pero no me mires asi\",\n  \"Hola, no me mires asi porque me desgasto\"\n]\n\n\nconnect(\"MQTT\", {\n  ...environment.mqtt,\n  topic: \"eva/camera/image\"\n}).pipe(\n  filter(x => x.message),\n  throttleTime(200),\n  base64ToBlob(),\n  blobToImage,\n  map(({message: img, connection}) => {\n    const landmarks = poseLandmarker.detect(img).;\n    console.log(landmarks);\n    if (faceLandmarks.length === 0) {\n      connection.send({topic: \"eva/neck/animation\", message:  \"c\"});\n      return {message: null, connection};\n    }\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    if (relativeDistance <= threshold)\n      return {message: null, connection};\n    connection.send({topic: \"eva/neck/animation\", message:  distance > 0 ? \"r\" : \"l\"});\n    return {message: math.distance([x,y,z], [0,0,0]), connection};\n  }),\n  filter(x => x.message && x.message <= 1.2),\n  throttleTime(7000),\n  tap(({connection}) => {\n    connection.send({topic: \"hermes/tts/say\", message: serialize({text: greetings[randint(0,greetings.length)]})})\n  })\n)",
                      "language": "javascript",
                      "output": "Uncaught ReferenceError: faceLandmarks is not defined\n"
                    },
                    "index": 7,
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618769882.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n  PoseLandmarker,\n  FilesetResolver,\n  DrawingUtils\n} from \"https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n\nconst poseLandmarker = await PoseLandmarker.createFromOptions(vision, {\n    baseOptions: {\n      modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task`,\n      delegate: \"GPU\"\n    },\n    runningMode: \"IMAGE\",\n    numPoses: 2\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.3;\n\n\nconst greetings = [\n  \"Hola, que puedo hacer por ti hoy?\",\n  \"Buenas tardes\",\n  \"Estimado, como puedo ayudarte?\",\n  \"Hola, por que me miras? Se que soy hermosa, pero no me mires asi\",\n  \"Hola, no me mires asi porque me desgasto\"\n]\n\n\nconnect(\"MQTT\", {\n  ...environment.mqtt,\n  topic: \"eva/camera/image\"\n}).pipe(\n  filter(x => x.message),\n  throttleTime(200),\n  base64ToBlob(),\n  blobToImage,\n  map(({message: img, connection}) => {\n    const landmarks = poseLandmarker.detect(img).lan;\n    console.log(landmarks);\n    if (faceLandmarks.length === 0) {\n      connection.send({topic: \"eva/neck/animation\", message:  \"c\"});\n      return {message: null, connection};\n    }\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    if (relativeDistance <= threshold)\n      return {message: null, connection};\n    connection.send({topic: \"eva/neck/animation\", message:  distance > 0 ? \"r\" : \"l\"});\n    return {message: math.distance([x,y,z], [0,0,0]), connection};\n  }),\n  filter(x => x.message && x.message <= 1.2),\n  throttleTime(7000),\n  tap(({connection}) => {\n    connection.send({topic: \"hermes/tts/say\", message: serialize({text: greetings[randint(0,greetings.length)]})})\n  })\n)",
                      "language": "javascript",
                      "output": "Uncaught ReferenceError: faceLandmarks is not defined\n"
                    },
                    "index": 7,
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618771066.06
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n  PoseLandmarker,\n  FilesetResolver,\n  DrawingUtils\n} from \"https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n\nconst poseLandmarker = await PoseLandmarker.createFromOptions(vision, {\n    baseOptions: {\n      modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task`,\n      delegate: \"GPU\"\n    },\n    runningMode: \"IMAGE\",\n    numPoses: 2\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.3;\n\n\nconst greetings = [\n  \"Hola, que puedo hacer por ti hoy?\",\n  \"Buenas tardes\",\n  \"Estimado, como puedo ayudarte?\",\n  \"Hola, por que me miras? Se que soy hermosa, pero no me mires asi\",\n  \"Hola, no me mires asi porque me desgasto\"\n]\n\n\nconnect(\"MQTT\", {\n  ...environment.mqtt,\n  topic: \"eva/camera/image\"\n}).pipe(\n  filter(x => x.message),\n  throttleTime(200),\n  base64ToBlob(),\n  blobToImage,\n  map(({message: img, connection}) => {\n    const landmarks = poseLandmarker.detect(img).land;\n    console.log(landmarks);\n    if (faceLandmarks.length === 0) {\n      connection.send({topic: \"eva/neck/animation\", message:  \"c\"});\n      return {message: null, connection};\n    }\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    if (relativeDistance <= threshold)\n      return {message: null, connection};\n    connection.send({topic: \"eva/neck/animation\", message:  distance > 0 ? \"r\" : \"l\"});\n    return {message: math.distance([x,y,z], [0,0,0]), connection};\n  }),\n  filter(x => x.message && x.message <= 1.2),\n  throttleTime(7000),\n  tap(({connection}) => {\n    connection.send({topic: \"hermes/tts/say\", message: serialize({text: greetings[randint(0,greetings.length)]})})\n  })\n)",
                      "language": "javascript",
                      "output": "Uncaught ReferenceError: faceLandmarks is not defined\n"
                    },
                    "index": 7,
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618771650.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n  PoseLandmarker,\n  FilesetResolver,\n  DrawingUtils\n} from \"https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n\nconst poseLandmarker = await PoseLandmarker.createFromOptions(vision, {\n    baseOptions: {\n      modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task`,\n      delegate: \"GPU\"\n    },\n    runningMode: \"IMAGE\",\n    numPoses: 2\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.3;\n\n\nconst greetings = [\n  \"Hola, que puedo hacer por ti hoy?\",\n  \"Buenas tardes\",\n  \"Estimado, como puedo ayudarte?\",\n  \"Hola, por que me miras? Se que soy hermosa, pero no me mires asi\",\n  \"Hola, no me mires asi porque me desgasto\"\n]\n\n\nconnect(\"MQTT\", {\n  ...environment.mqtt,\n  topic: \"eva/camera/image\"\n}).pipe(\n  filter(x => x.message),\n  throttleTime(200),\n  base64ToBlob(),\n  blobToImage,\n  map(({message: img, connection}) => {\n    const landmarks = poseLandmarker.detect(img).landm;\n    console.log(landmarks);\n    if (faceLandmarks.length === 0) {\n      connection.send({topic: \"eva/neck/animation\", message:  \"c\"});\n      return {message: null, connection};\n    }\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    if (relativeDistance <= threshold)\n      return {message: null, connection};\n    connection.send({topic: \"eva/neck/animation\", message:  distance > 0 ? \"r\" : \"l\"});\n    return {message: math.distance([x,y,z], [0,0,0]), connection};\n  }),\n  filter(x => x.message && x.message <= 1.2),\n  throttleTime(7000),\n  tap(({connection}) => {\n    connection.send({topic: \"hermes/tts/say\", message: serialize({text: greetings[randint(0,greetings.length)]})})\n  })\n)",
                      "language": "javascript",
                      "output": "Uncaught ReferenceError: faceLandmarks is not defined\n"
                    },
                    "index": 7,
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618772170.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n  PoseLandmarker,\n  FilesetResolver,\n  DrawingUtils\n} from \"https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n\nconst poseLandmarker = await PoseLandmarker.createFromOptions(vision, {\n    baseOptions: {\n      modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task`,\n      delegate: \"GPU\"\n    },\n    runningMode: \"IMAGE\",\n    numPoses: 2\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.3;\n\n\nconst greetings = [\n  \"Hola, que puedo hacer por ti hoy?\",\n  \"Buenas tardes\",\n  \"Estimado, como puedo ayudarte?\",\n  \"Hola, por que me miras? Se que soy hermosa, pero no me mires asi\",\n  \"Hola, no me mires asi porque me desgasto\"\n]\n\n\nconnect(\"MQTT\", {\n  ...environment.mqtt,\n  topic: \"eva/camera/image\"\n}).pipe(\n  filter(x => x.message),\n  throttleTime(200),\n  base64ToBlob(),\n  blobToImage,\n  map(({message: img, connection}) => {\n    const landmarks = poseLandmarker.detect(img).landmarks;\n    console.log(landmarks);\n    if (faceLandmarks.length === 0) {\n      connection.send({topic: \"eva/neck/animation\", message:  \"c\"});\n      return {message: null, connection};\n    }\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    if (relativeDistance <= threshold)\n      return {message: null, connection};\n    connection.send({topic: \"eva/neck/animation\", message:  distance > 0 ? \"r\" : \"l\"});\n    return {message: math.distance([x,y,z], [0,0,0]), connection};\n  }),\n  filter(x => x.message && x.message <= 1.2),\n  throttleTime(7000),\n  tap(({connection}) => {\n    connection.send({topic: \"hermes/tts/say\", message: serialize({text: greetings[randint(0,greetings.length)]})})\n  })\n)",
                      "language": "javascript",
                      "output": "Uncaught ReferenceError: faceLandmarks is not defined\n"
                    },
                    "index": 7,
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618773076.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n  PoseLandmarker,\n  FilesetResolver,\n  DrawingUtils\n} from \"https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n\nconst poseLandmarker = await PoseLandmarker.createFromOptions(vision, {\n    baseOptions: {\n      modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task`,\n      delegate: \"GPU\"\n    },\n    runningMode: \"IMAGE\",\n    numPoses: 2\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.3;\n\n\nconst greetings = [\n  \"Hola, que puedo hacer por ti hoy?\",\n  \"Buenas tardes\",\n  \"Estimado, como puedo ayudarte?\",\n  \"Hola, por que me miras? Se que soy hermosa, pero no me mires asi\",\n  \"Hola, no me mires asi porque me desgasto\"\n]\n\n\nconnect(\"MQTT\", {\n  ...environment.mqtt,\n  topic: \"eva/camera/image\"\n}).pipe(\n  filter(x => x.message),\n  throttleTime(200),\n  base64ToBlob(),\n  blobToImage,\n  map(({message: img, connection}) => {\n    const landmarks = poseLandmarker.detect(img).landmarks;\n    console.log(landmarks);\n    if (landmarks.length === 0) {\n      connection.send({topic: \"eva/neck/animation\", message:  \"c\"});\n      return {message: null, connection};\n    }\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    if (relativeDistance <= threshold)\n      return {message: null, connection};\n    connection.send({topic: \"eva/neck/animation\", message:  distance > 0 ? \"r\" : \"l\"});\n    return {message: math.distance([x,y,z], [0,0,0]), connection};\n  }),\n  filter(x => x.message && x.message <= 1.2),\n  throttleTime(7000),\n  tap(({connection}) => {\n    connection.send({topic: \"hermes/tts/say\", message: serialize({text: greetings[randint(0,greetings.length)]})})\n  })\n)",
                      "language": "javascript",
                      "output": "Uncaught ReferenceError: faceLandmarks is not defined\n"
                    },
                    "index": 7,
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618778610.02
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n  PoseLandmarker,\n  FilesetResolver,\n  DrawingUtils\n} from \"https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n\nconst poseLandmarker = await PoseLandmarker.createFromOptions(vision, {\n    baseOptions: {\n      modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task`,\n      delegate: \"GPU\"\n    },\n    runningMode: \"IMAGE\",\n    numPoses: 2\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.3;\n\n\nconst greetings = [\n  \"Hola, que puedo hacer por ti hoy?\",\n  \"Buenas tardes\",\n  \"Estimado, como puedo ayudarte?\",\n  \"Hola, por que me miras? Se que soy hermosa, pero no me mires asi\",\n  \"Hola, no me mires asi porque me desgasto\"\n]\n\n\nconnect(\"MQTT\", {\n  ...environment.mqtt,\n  topic: \"eva/camera/image\"\n}).pipe(\n  filter(x => x.message),\n  throttleTime(200),\n  base64ToBlob(),\n  blobToImage,\n  map(({message: img, connection}) => {\n    const landmarks = poseLandmarker.detect(img).landmarks;\n    if (landmarks.length === 0) {\n      connection.send({topic: \"eva/neck/animation\", message:  \"c\"});\n      return {message: null, connection};\n    }\n    const [x,y,z] = calculateCentroid(faceLandmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    if (relativeDistance <= threshold)\n      return {message: null, connection};\n    connection.send({topic: \"eva/neck/animation\", message:  distance > 0 ? \"r\" : \"l\"});\n    return {message: math.distance([x,y,z], [0,0,0]), connection};\n  }),\n  filter(x => x.message && x.message <= 1.2),\n  throttleTime(7000),\n  tap(({connection}) => {\n    connection.send({topic: \"hermes/tts/say\", message: serialize({text: greetings[randint(0,greetings.length)]})})\n  })\n)",
                      "language": "javascript",
                      "output": "Uncaught ReferenceError: faceLandmarks is not defined\n"
                    },
                    "index": 7,
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618781629.01
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n  PoseLandmarker,\n  FilesetResolver,\n  DrawingUtils\n} from \"https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n\nconst poseLandmarker = await PoseLandmarker.createFromOptions(vision, {\n    baseOptions: {\n      modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task`,\n      delegate: \"GPU\"\n    },\n    runningMode: \"IMAGE\",\n    numPoses: 2\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.3;\n\n\nconst greetings = [\n  \"Hola, que puedo hacer por ti hoy?\",\n  \"Buenas tardes\",\n  \"Estimado, como puedo ayudarte?\",\n  \"Hola, por que me miras? Se que soy hermosa, pero no me mires asi\",\n  \"Hola, no me mires asi porque me desgasto\"\n]\n\n\nconnect(\"MQTT\", {\n  ...environment.mqtt,\n  topic: \"eva/camera/image\"\n}).pipe(\n  filter(x => x.message),\n  throttleTime(200),\n  base64ToBlob(),\n  blobToImage,\n  map(({message: img, connection}) => {\n    const landmarks = poseLandmarker.detect(img).landmarks;\n    if (landmarks.length === 0) {\n      connection.send({topic: \"eva/neck/animation\", message:  \"c\"});\n      return {message: null, connection};\n    }\n    const [x,y,z] = calculateCentroid(landmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    if (relativeDistance <= threshold)\n      return {message: null, connection};\n    connection.send({topic: \"eva/neck/animation\", message:  distance > 0 ? \"r\" : \"l\"});\n    return {message: math.distance([x,y,z], [0,0,0]), connection};\n  }),\n  filter(x => x.message && x.message <= 1.2),\n  throttleTime(7000),\n  tap(({connection}) => {\n    connection.send({topic: \"hermes/tts/say\", message: serialize({text: greetings[randint(0,greetings.length)]})})\n  })\n)",
                      "language": "javascript",
                      "output": "Uncaught ReferenceError: faceLandmarks is not defined\n"
                    },
                    "index": 7,
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618784346.05
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "data": {
                      "code": "import {\n  PoseLandmarker,\n  FilesetResolver,\n  DrawingUtils\n} from \"https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.0\";\n\nconst filesetResolver = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n);\n\n/* \n   TODO: I think this function introduce a high overhead, so it should be migrated to WASM C.\n*/\nfunction calculateCentroid(landmarks) {\n    const sum = landmarks.reduce((acc, landmark) => {\n        acc[0] = landmark.x + acc[0];\n        acc[1] = landmark.y + acc[1];\n        acc[2] = landmark.z + acc[2];\n        return acc;\n    }, [0, 0, 0]);\n    return sum.map(coord => coord / landmarks.length);\n}\n\nconst vision = await FilesetResolver.forVisionTasks(\n    \"https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm\"\n  );\n\nconst poseLandmarker = await PoseLandmarker.createFromOptions(vision, {\n    baseOptions: {\n      modelAssetPath: `https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task`,\n      delegate: \"GPU\"\n    },\n    runningMode: \"IMAGE\",\n    numPoses: 2\n});\n\n\nconst visionLine = 0.5;\nconst threshold = 0.3;\n\n\nconst greetings = [\n  \"Hola, que puedo hacer por ti hoy?\",\n  \"Buenas tardes\",\n  \"Estimado, como puedo ayudarte?\",\n  \"Hola, por que me miras? Se que soy hermosa, pero no me mires asi\",\n  \"Hola, no me mires asi porque me desgasto\"\n]\n\n\nconnect(\"MQTT\", {\n  ...environment.mqtt,\n  topic: \"eva/camera/image\"\n}).pipe(\n  filter(x => x.message),\n  throttleTime(200),\n  base64ToBlob(),\n  blobToImage,\n  map(({message: img, connection}) => {\n    const landmarks = poseLandmarker.detect(img).landmarks;\n    if (landmarks.length === 0) {\n      connection.send({topic: \"eva/neck/animation\", message:  \"c\"});\n      return {message: null, connection};\n    }\n    const [x,y,z] = calculateCentroid(landmarks[0]);\n    const distance = visionLine-x;\n    const relativeDistance = Math.abs(distance)/x;\n    if (relativeDistance <= threshold)\n      return {message: null, connection};\n    connection.send({topic: \"eva/neck/animation\", message:  distance > 0 ? \"r\" : \"l\"});\n    return {message: math.distance([x,y,z], [0,0,0]), connection};\n  }),\n  filter(x => x.message && x.message <= 1.2),\n  throttleTime(7000),\n  tap(({connection}) => {\n    connection.send({topic: \"hermes/tts/say\", message: serialize({text: greetings[randint(0,greetings.length)]})})\n  })\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 7,
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "_deleted": false
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618785641.06
          }
        ]
      ],
      "hash": "d8a0c62c07ca2ef3dfcaeb9f8e581a79a6ea17a5c40c2079ee280fc6d0f0ae26"
    },
    "_meta": {
      "lwt": 1684618785642.01
    },
    "_deleted": false,
    "_attachments": {},
    "_rev": "30-maejjbxwtp"
  },
  {
    "id": "IFTDfoOXQb",
    "type": "header",
    "data": {
      "text": "Replication",
      "level": 1
    },
    "index": 8,
    "createdBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
    "topic": "24e59b27-632c-46f6-8b46-123d3e92815b",
    "crdts": {
      "operations": [
        [
          {
            "creator": "fvaguydpuy",
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "id": "IFTDfoOXQb",
                    "type": "header",
                    "data": {
                      "text": "Replication",
                      "level": 1
                    },
                    "index": 8,
                    "createdBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "topic": "24e59b27-632c-46f6-8b46-123d3e92815b"
                  }
                }
              }
            ],
            "time": 1684618359669.09
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "index": 8
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618537824.01
          }
        ]
      ],
      "hash": "e07cb87d1b0425f28cea9900c006b1fed995d1c051d6d6bcbbcec85ad952dd5f"
    },
    "_meta": {
      "lwt": 1684618537824.1
    },
    "_deleted": false,
    "_attachments": {},
    "_rev": "2-alwuqujhxp"
  },
  {
    "id": "EWrIE6Gc7y",
    "type": "code",
    "data": {
      "code": "const options = {\n    owner: \"lozanoernesto\",\n    repo: \"evanotebooks\",\n    filePath: \"9-track-human-real-time.json\",\n    commitMessage: \"feat: send action over MQTT\",\n    GITHUB_TOKEN: environment.GITHUB_TOKEN\n}\n\neditor.blocks.get$.pipe(\n  first(),\n  map(content =>\n    btoa(unescape(encodeURIComponent(JSON.stringify(content, null, 2).replaceAll(environment.GITHUB_TOKEN, \"\"))))),\n  commitOnGitHub(options)\n)",
      "language": "javascript",
      "output": ""
    },
    "index": 9,
    "createdBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
    "topic": "24e59b27-632c-46f6-8b46-123d3e92815b",
    "crdts": {
      "operations": [
        [
          {
            "creator": "fvaguydpuy",
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "id": "EWrIE6Gc7y",
                    "type": "code",
                    "data": {
                      "code": "const options = {\n    owner: \"lozanoernesto\",\n    repo: \"evanotebooks\",\n    filePath: \"9-track-human-real-time.json\",\n    commitMessage: \"feat: send action over MQTT\",\n    GITHUB_TOKEN: environment.GITHUB_TOKEN\n}\n\neditor.blocks.get$.pipe(\n  first(),\n  map(content =>\n    btoa(unescape(encodeURIComponent(JSON.stringify(content, null, 2).replaceAll(environment.GITHUB_TOKEN, \"\"))))),\n  commitOnGitHub(options)\n)",
                      "language": "javascript",
                      "output": ""
                    },
                    "index": 9,
                    "createdBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "topic": "24e59b27-632c-46f6-8b46-123d3e92815b"
                  }
                }
              }
            ],
            "time": 1684618359669.1
          }
        ],
        [
          {
            "body": [
              {
                "ifMatch": {
                  "$set": {
                    "lastEditedBy": "c4924e4b-2e55-4f9b-bf11-e67e6d7f2d10",
                    "index": 9
                  }
                }
              }
            ],
            "creator": "fvaguydpuy",
            "time": 1684618537824.02
          }
        ]
      ],
      "hash": "e07cb87d1b0425f28cea9900c006b1fed995d1c051d6d6bcbbcec85ad952dd5f"
    },
    "_meta": {
      "lwt": 1684618537824.11
    },
    "_deleted": false,
    "_attachments": {},
    "_rev": "2-alwuqujhxp"
  }
]